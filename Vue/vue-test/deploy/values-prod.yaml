# Default prod values.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Every time you modify the values, you need to modify the changeCause to indicate the reason for the change
changeCause: "new"

# Basic info
Chart:
  appversion: v1.0.0 # Your image's version
  version: 1.0.0 # Your chart's version. Every time you modify values, you need to update a appropriate version number
  releasename: finance-products-frontend # Your release name, your chart's name
  maintainers:
    email: lijian_yuan@shannonai.com # Your email
    name: yuanlijian # Your name

minReadySeconds: 0 # The time from the program's liveness health to service availability, generally set to 0
progressDeadlineSeconds: 120 # How long the deployment stuck in a failed state it would be considered a failure
revisionHistoryLimit: 7
replicas: 1 # Number of desired pod, increase or decrease the number of pods as needed

# Use strategy to configure rolling updates
strategy:
  type: "RollingUpdate" # RollingUpdate, Recreate
  maxSurge: 1 # 1, 5, 10,  30%, 50%... The number of pods that can be created above the desired amount of pods during an update
  maxUnavailable: 0 # 1, 5, 10,  30%, 50%... The number of pods that can be unavailable during the update process

pod:
  terminationGracePeriodSeconds: 30 # The time of pods exit gracefully
  imagePullSecrets: "harbor-kubernetes" # docker registry account，default use harbor.shannonai.com, it's secrets called harbor-kubernetes
# If you need to open readygo automatic discovery, you need to delete the "[]" behind the annotations, delete the "#" below and configure the following three indicators for the correct prometheus metric
  annotations: []
#   prometheus.io/readygo_scrape: "true"
#   prometheus.io/port: "your metric port"
#   prometheus.io/path: "your metric path"

nodeSelector:  # Use nodeSelector for scheduling a pod to a special node
  environment: "production"

tolerations:  # Use tolerations to tolerate some existing taints
  - key: "environment"
    operator: "Equal"
    value: "production"
    effect: "NoSchedule"

# Image of your program
image:
  repository: "harbor.shannonai.com/frontend/finance-products-frontend" # do not add '/' to the end
  pullPolicy: Always # IfNotPresent, Always
  command: [] # replace entrypoint in image, for example: command: ["echo"]
  args: [] # arguments for entrypoint, for example: args: ["arg1", "arg2"]

# Whether to use init container(for downloading data or mounting Configuration)
kubeInit:
  enabled: false
  image: "harbor.shannonai.com/shannon/kube-init:v1.2.6"
  pullPolicy: IfNotPresent
  command: []  # replace entrypoint in image, for example: command: ["echo"]
  args: ["init"] # arguments for entrypoint, for example: args: ["arg1", "arg2"]

# If the liveness probe fails, the container will be restarted
livenessProbe: {}


# If the readiness Probe fails, the container will be marked as unready
readinessProbe: {}


# Setting the container's environment variables
env: []
#- name: "KEY1"
#  value: "VALUE1"
#- name: "KEY2"
#  value: "VALUE2"

# Exposing services
service:
  enabled: true
  isHeadLess: false # Whether it is a headless service, used for DNS-based service discovery. Only effective in ClusterIP mode
  type: ClusterIP # ClusterIP, NodePort
  externalTrafficPolicy: Local # Local, Cluster. Only for type is NodePort

# Multi-ports need to follow the same format, continue to configure, see the example below
ports:
  app: # Will be used as the name of the service(default "app"), just named as your application name
    port: 8080 # The port exposed on the ClusterIP. Users in the cluster use <cluster ip>: <port> to access the service.
    targetPort: 8080 # The port exposed on the pod, should be same as 'containerPort'(EXPOSED port in Dockerfile)
    nodePort: 8080 # The port exposed on the host machine, users outside the cluster use <host ip>: <nodePort> to access the service
    protocol: TCP
# portname2:
#   port: 8080 # The port exposed on the ClusterIP. Users in the cluster use <cluster ip>: <port> to access the service.
#   targetPort: 8080 # The port exposed on the pod, should be same as 'containerPort'(EXPOSED port in Dockerfile)
#   nodePort: 8080 # The port exposed on the host machine, users outside the cluster use <host ip>: <nodePort> to access the service
#   protocol: TCP

# Set the domain name
ingress:
  enabled: true # Set to false if external network access is not required
  annotations:
    kubernetes.io/ingress.class: traefik-prod
  # traefik.ingress.kubernetes.io/app-root: your root uri
  paths: ["/"] # Access path
  hosts:
    - finance-products.shannonai.com # Domain name
  servicePort: 8080 # Should be the same as '.Values.service.port'
  tls: []

# Resource limits for instances
# After the chart is released, according to the actual resource occupation displayed in grafana, modify the resource request/limit in time to avoid resource wasting
# monitor address: https://grafana-nx.shannonai.com
resources: # {}
  limits:
    cpu: "200m" # CPU limit, such as 100m, 500m, 1, 2, ...
    memory: "600Mi" # MEM limit, such as 50Mi, 1Gi
    ephemeral-storage: "2Gi" # Disk limit(almost for temporary storage and log), such as 50Mi, 1Gi
#   aliyun.com/gpu-mem: 6 # GPU-share
  requests:
    cpu: "100m" # 100m, 500m, 1, 2, ...
    memory: "300Mi"
    ephemeral-storage: "1Gi"

volumeMounts:
- name: data-volume
  mountPath: /home/work/data
- name: logs-volume
  mountPath: /home/work/logs
- name: configmap-volume
  mountPath: /home/work/conf/static-webserver.yaml
  subPath: static-webserver.yaml

volumes:
- name: data-volume
  emptyDir: {} # If using PVC, please have a look at 'https://bit.ly/2YuDK3V'
   # If using PVC, please have a look at 'https://bit.ly/2YuDK3V'
- name: logs-volume
  emptyDir: {}

# If you want to put data into the pod before the service starts, you need set "storage.enabled: true", and set correct storage path
# Application for storage： @yanhonglei @zhangsiming
storage:
  enabled: false
  storage_dir: /data/storage/DEPARTMENT/PROJECTNAME # Please change this to the relevant share, need to be created in advance(in remote storage)
  pod_dir: /home/work/storage # Please change the destination you like the share to be mounted(in pod)

pvc:
  enabled: false # If you use an existing PVC, you can set it to false and modify the volumes above.
  storageClass: "nfs-10-20-11-105" # Such as nfs-172-31-21-2
  accessMode: ReadWriteOnce # ReadWriteOnce, ReadOnlyMany, ReadWriteMany. The accessModes of PV and PVC must be the same
  size: 8Gi

pdb: # PodDisruptionBudget, used for pod active eviction protection, note that after pdb is determined, it cannot be updated
  enabled: true
  maxUnavailable: 1 # MaxUnavailable and minAvailable cannot be used at the same time. Values: 1, 30%, etc.
  minAvailable: ""

# The Horizontal Pod Autoscaler automatically scales the number of pods to avoid CPU/MEM utilization over 100%(request) when having a heavy pressusre
# The min replica number is 1 and max number is 5
# Set "hpa.enabled=true" to enable
hpa:
  enabled: false
  minReplicas: 1 # Maximum and minimum number of replicas when scaling out
  maxReplicas: 5

# Program's config file
configmap:
  enabled: true
  content:
    # The configuration file name is data.url and the mount path is /home/work/conf/data.url, use for init container to download file to /home/work/data
    # 'example-conf.yaml' is a example name for your configfile, you can change it to whatever you want.
    # The content of your config file needs to be fully pasted under the config file name, and two more spaces are required for indentation; If more config files are needed, please write in a similar format below
    static-webserver.yaml: |
      port: 8080
      log:
        level: INFO # DEBUG, INFO, WARN, ERROR
        encoding: json
        outputPaths: ['alertplatform.log'] # only active in non-debug mode
        errorOutputPaths: ['alertplatform.err.log'] # only active in non-debug mode
      gin:
        staticPath: assets # 设置静态目录
        notFoundPage: assets/index.html  # 设置 404 页面
        notFoundCode: 200 # 设置page not found 时，要返回的状态码
        consoleColor: false # gin 输出日志是否显示颜色
        level: INFO # DEBUG, INFO, WARN, ERROR
        logfile: logs/access.log

